{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Statistics (correlation)\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# libraries for the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:04:02.532279655Z",
     "start_time": "2023-12-17T20:04:02.497541546Z"
    }
   },
   "id": "faa5c3bcb1688008"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# custom functions\n",
    "from pt_helpers import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:04:04.199652514Z",
     "start_time": "2023-12-17T20:04:04.173984785Z"
    }
   },
   "id": "8a68bef39b0bfff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the training data\n",
    "This is the clean data that we processed in the notebook `Training_data_preparation`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7328aa353a464bc"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "data_path = \"DATA/training_data/\"\n",
    "\n",
    "df = pd.read_csv(data_path + \"VEX_edac_mag_labeled.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:10:03.949547939Z",
     "start_time": "2023-12-17T20:10:02.327285050Z"
    }
   },
   "id": "1db39c6398d42927"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "             DATE_TIME  EDAC         BX        BY        BZ         BT  \\\n0  2006-04-24 00:00:00     0  12.357658 -1.304164 -3.332425  12.881274   \n1  2006-04-24 00:05:00     0  12.868947 -0.980800 -3.360027  13.340680   \n2  2006-04-24 00:10:00     0  12.857438 -0.871986 -3.487877  13.355384   \n3  2006-04-24 00:15:00     0  12.898635 -0.684986 -2.885689  13.248405   \n4  2006-04-24 00:20:00     0  12.766473 -0.517608 -2.217135  12.972905   \n\n           XSC          YSC           ZSC           RSC  cme  \n0 -4451.055178 -3196.485753 -65466.762260  65695.760575    0  \n1 -4202.246280 -3138.377907 -65806.350827  66015.078600    0  \n2 -3954.000329 -3080.233288 -66137.913808  66327.612616    0  \n3 -3705.057257 -3021.761270 -66463.291041  66635.079608    0  \n4 -3453.676541 -2962.553108 -66784.717784  66939.596338    0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DATE_TIME</th>\n      <th>EDAC</th>\n      <th>BX</th>\n      <th>BY</th>\n      <th>BZ</th>\n      <th>BT</th>\n      <th>XSC</th>\n      <th>YSC</th>\n      <th>ZSC</th>\n      <th>RSC</th>\n      <th>cme</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2006-04-24 00:00:00</td>\n      <td>0</td>\n      <td>12.357658</td>\n      <td>-1.304164</td>\n      <td>-3.332425</td>\n      <td>12.881274</td>\n      <td>-4451.055178</td>\n      <td>-3196.485753</td>\n      <td>-65466.762260</td>\n      <td>65695.760575</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2006-04-24 00:05:00</td>\n      <td>0</td>\n      <td>12.868947</td>\n      <td>-0.980800</td>\n      <td>-3.360027</td>\n      <td>13.340680</td>\n      <td>-4202.246280</td>\n      <td>-3138.377907</td>\n      <td>-65806.350827</td>\n      <td>66015.078600</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2006-04-24 00:10:00</td>\n      <td>0</td>\n      <td>12.857438</td>\n      <td>-0.871986</td>\n      <td>-3.487877</td>\n      <td>13.355384</td>\n      <td>-3954.000329</td>\n      <td>-3080.233288</td>\n      <td>-66137.913808</td>\n      <td>66327.612616</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2006-04-24 00:15:00</td>\n      <td>0</td>\n      <td>12.898635</td>\n      <td>-0.684986</td>\n      <td>-2.885689</td>\n      <td>13.248405</td>\n      <td>-3705.057257</td>\n      <td>-3021.761270</td>\n      <td>-66463.291041</td>\n      <td>66635.079608</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2006-04-24 00:20:00</td>\n      <td>0</td>\n      <td>12.766473</td>\n      <td>-0.517608</td>\n      <td>-2.217135</td>\n      <td>12.972905</td>\n      <td>-3453.676541</td>\n      <td>-2962.553108</td>\n      <td>-66784.717784</td>\n      <td>66939.596338</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T20:10:05.763987641Z",
     "start_time": "2023-12-17T20:10:05.721205790Z"
    }
   },
   "id": "7fb5031b6e6165cb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We separate the feature matrix `X` and the labels `y`.\n",
    "- `X` will contain X Y and Z coordinates of the magnetic field"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4644fd75bc7077f"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "y = df['cme'].values\n",
    "# Normalize the features\n",
    "X = df[['BT', 'RSC']].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T14:35:13.565009686Z",
     "start_time": "2023-12-17T14:35:13.528605087Z"
    }
   },
   "id": "54936c92e8d160c3"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y: (904224,)\n",
      "Shape of X: (904224, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of y:\", y.shape)\n",
    "print(\"Shape of X:\", X.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T14:35:14.837008190Z",
     "start_time": "2023-12-17T14:35:14.806958116Z"
    }
   },
   "id": "1d13df463988fea2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSTM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efce66efdacb6f49"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum y: nan\n",
      "Shape of X and y sequences: (904188, 36, 2) (904188,)\n",
      "Shape of X and y sequences after dropping nans: (893033, 36, 2) (893033,)\n",
      "Sum y_seq: 15939.0\n"
     ]
    }
   ],
   "source": [
    "time_steps = 36  # 3 hours of data\n",
    "X_seq, y_seq = create_sequences(X, y, time_steps)\n",
    "print(\"Shape of X and y sequences:\", X_seq.shape, y_seq.shape)\n",
    "# Drop all row containing nans\n",
    "X_seq = X_seq[~np.isnan(X_seq).any(axis=-1)]\n",
    "X_seq = X_seq.reshape(-1, time_steps, X_seq.shape[1])\n",
    "y_seq = y_seq[~np.isnan(y_seq)]\n",
    "print(\"Shape of X and y sequences after dropping nans:\", X_seq.shape, y_seq.shape)\n",
    "print(\"Sum y_seq:\", np.sum(y_seq))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T14:41:35.458135863Z",
     "start_time": "2023-12-17T14:41:33.035002920Z"
    }
   },
   "id": "800ba9844ba4f088"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "class CMEPredictor(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden=50, n_layers=2):\n",
    "        super(CMEPredictor, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=n_features, hidden_size=n_hidden, num_layers=n_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(n_hidden, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x[:, -1, :])\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "n_features = X_seq.shape[2]  # Number of features in the dataset\n",
    "model = CMEPredictor(n_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T14:23:37.812763614Z",
     "start_time": "2023-12-17T14:23:37.778044621Z"
    }
   },
   "id": "5c4e733b6f2da49c"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Standardize the data\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train.reshape(-1, n_features)).reshape(-1, time_steps, n_features)\n",
    "# X_val = scaler.transform(X_val.reshape(-1, n_features)).reshape(-1, time_steps, n_features)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_data = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "val_data = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T14:23:38.095696275Z",
     "start_time": "2023-12-17T14:23:37.803039616Z"
    }
   },
   "id": "762fbf7470ad8b21"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 32  # Adjust this based on your system's capability\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T14:23:38.129209036Z",
     "start_time": "2023-12-17T14:23:38.097303193Z"
    }
   },
   "id": "4159523def554290"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "n_epochs = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T14:23:38.153747572Z",
     "start_time": "2023-12-17T14:23:38.130165362Z"
    }
   },
   "id": "303d28ccaa6a5914"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training and evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bc274d1a8ab9d54"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.017840756103396416, Val Loss: 0.06819538405116359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop with reduced batch size and data loading on-the-fly\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            val_output = model(X_batch)\n",
    "            val_loss += criterion(val_output, y_batch.view(-1, 1)).item()\n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}, Val Loss: {val_loss}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T14:28:14.400482407Z",
     "start_time": "2023-12-17T14:23:38.156569990Z"
    }
   },
   "id": "ec91deadb754a102"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        outputs = model(X_batch)\n",
    "        predicted = (outputs > 0.5).float()  # Using 0.5 as the threshold for binary classification\n",
    "        predictions.extend(predicted.view(-1).tolist())\n",
    "        true_labels.extend(y_batch.tolist())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "f1 = f1_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions)\n",
    "recall = recall_score(true_labels, predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-17T14:28:14.394267650Z"
    }
   },
   "id": "ec1f92c6c92f5abe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSTM with class weights"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84311acccabbaabc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "# Use the class weights in your loss function\n",
    "criterion = nn.BCELoss(weight=class_weights[1])  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-17T14:28:14.394438254Z"
    }
   },
   "id": "a1238d1dfabca5a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            val_output = model(X_batch)\n",
    "            val_loss += criterion(val_output, y_batch.view(-1, 1)).item()\n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}, Val Loss: {val_loss}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-17T14:28:14.394540174Z"
    }
   },
   "id": "d32ae591a75b4878"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        outputs = model(X_batch)\n",
    "        predicted = (outputs > 0.5).float()  # Using 0.5 as the threshold for binary classification\n",
    "        predictions.extend(predicted.view(-1).tolist())\n",
    "        true_labels.extend(y_batch.tolist())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "f1 = f1_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions)\n",
    "recall = recall_score(true_labels, predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-17T14:28:14.394606388Z"
    }
   },
   "id": "3c353ad855470f4f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
