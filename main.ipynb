{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Statistics (correlation)\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# libraries for the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions\n",
    "from pt_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data\n",
    "This is the clean data that we processed in the notebook `Training_data_preparation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"DATA/training_data/\"\n",
    "\n",
    "df = pd.read_csv(data_path + \"VEX_edac_mag_labeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>EDAC</th>\n",
       "      <th>BX</th>\n",
       "      <th>BY</th>\n",
       "      <th>BZ</th>\n",
       "      <th>BT</th>\n",
       "      <th>XSC</th>\n",
       "      <th>YSC</th>\n",
       "      <th>ZSC</th>\n",
       "      <th>RSC</th>\n",
       "      <th>cme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-04-24 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>12.357658</td>\n",
       "      <td>-1.304164</td>\n",
       "      <td>-3.332425</td>\n",
       "      <td>12.881274</td>\n",
       "      <td>-4451.055178</td>\n",
       "      <td>-3196.485753</td>\n",
       "      <td>-65466.762260</td>\n",
       "      <td>65695.760575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-04-24 00:05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>12.868947</td>\n",
       "      <td>-0.980800</td>\n",
       "      <td>-3.360027</td>\n",
       "      <td>13.340680</td>\n",
       "      <td>-4202.246280</td>\n",
       "      <td>-3138.377907</td>\n",
       "      <td>-65806.350827</td>\n",
       "      <td>66015.078600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-04-24 00:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>12.857438</td>\n",
       "      <td>-0.871986</td>\n",
       "      <td>-3.487877</td>\n",
       "      <td>13.355384</td>\n",
       "      <td>-3954.000329</td>\n",
       "      <td>-3080.233288</td>\n",
       "      <td>-66137.913808</td>\n",
       "      <td>66327.612616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-04-24 00:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>12.898635</td>\n",
       "      <td>-0.684986</td>\n",
       "      <td>-2.885689</td>\n",
       "      <td>13.248405</td>\n",
       "      <td>-3705.057257</td>\n",
       "      <td>-3021.761270</td>\n",
       "      <td>-66463.291041</td>\n",
       "      <td>66635.079608</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-04-24 00:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>12.766473</td>\n",
       "      <td>-0.517608</td>\n",
       "      <td>-2.217135</td>\n",
       "      <td>12.972905</td>\n",
       "      <td>-3453.676541</td>\n",
       "      <td>-2962.553108</td>\n",
       "      <td>-66784.717784</td>\n",
       "      <td>66939.596338</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE_TIME  EDAC         BX        BY        BZ         BT  \\\n",
       "0  2006-04-24 00:00:00     0  12.357658 -1.304164 -3.332425  12.881274   \n",
       "1  2006-04-24 00:05:00     0  12.868947 -0.980800 -3.360027  13.340680   \n",
       "2  2006-04-24 00:10:00     0  12.857438 -0.871986 -3.487877  13.355384   \n",
       "3  2006-04-24 00:15:00     0  12.898635 -0.684986 -2.885689  13.248405   \n",
       "4  2006-04-24 00:20:00     0  12.766473 -0.517608 -2.217135  12.972905   \n",
       "\n",
       "           XSC          YSC           ZSC           RSC  cme  \n",
       "0 -4451.055178 -3196.485753 -65466.762260  65695.760575    0  \n",
       "1 -4202.246280 -3138.377907 -65806.350827  66015.078600    0  \n",
       "2 -3954.000329 -3080.233288 -66137.913808  66327.612616    0  \n",
       "3 -3705.057257 -3021.761270 -66463.291041  66635.079608    0  \n",
       "4 -3453.676541 -2962.553108 -66784.717784  66939.596338    0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate the feature matrix `X` and the labels `y`.\n",
    "- `X` will contain X Y and Z coordinates of the magnetic field and the distance from the sun RSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['cme'].values\n",
    "X = df[['BX', 'BY', 'BZ', 'RSC']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y: (893069,)\n",
      "Shape of X: (893069, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of y:\", y.shape)\n",
    "print(\"Shape of X:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 36  # 3 hours of data\n",
    "X_seq, y_seq = create_sequences(X, y, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMEPredictor(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden=50, n_layers=2):\n",
    "        super(CMEPredictor, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=n_features, hidden_size=n_hidden, num_layers=n_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(n_hidden, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x[:, -1, :])\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "n_features = X_seq.shape[2]  # Number of features in the dataset\n",
    "model = CMEPredictor(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, n_features)).reshape(-1, time_steps, n_features)\n",
    "X_val = scaler.transform(X_val.reshape(-1, n_features)).reshape(-1, time_steps, n_features)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_data = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "val_data = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 32  # Adjust this based on your system's capability\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.00594579940661788, Val Loss: 0.053774040349407456\n",
      "Epoch 2, Loss: 0.014139517210423946, Val Loss: 0.047800011793910635\n",
      "Epoch 3, Loss: 0.11722347140312195, Val Loss: 0.042304934381778625\n",
      "Epoch 4, Loss: 0.008344695903360844, Val Loss: 0.03521223705175729\n",
      "Epoch 5, Loss: 0.0020488000009208918, Val Loss: 0.03096859525075252\n",
      "Epoch 6, Loss: 0.013688743114471436, Val Loss: 0.026611497020232116\n",
      "Epoch 7, Loss: 0.011936815455555916, Val Loss: 0.02486511793823932\n",
      "Epoch 8, Loss: 0.0008495384827256203, Val Loss: 0.020216468520680368\n",
      "Epoch 9, Loss: 0.001588876242749393, Val Loss: 0.016796924547382366\n",
      "Epoch 10, Loss: 0.0004762269963975996, Val Loss: 0.012527251529922661\n"
     ]
    }
   ],
   "source": [
    "# Training loop with reduced batch size and data loading on-the-fly\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            val_output = model(X_batch)\n",
    "            val_loss += criterion(val_output, y_batch.view(-1, 1)).item()\n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}, Val Loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9962935383271653\n",
      "F1 Score: 0.8884770889487871\n",
      "Precision: 0.9387682449270203\n",
      "Recall: 0.8433002878157979\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        outputs = model(X_batch)\n",
    "        predicted = (outputs > 0.5).float()  # Using 0.5 as the threshold for binary classification\n",
    "        predictions.extend(predicted.view(-1).tolist())\n",
    "        true_labels.extend(y_batch.tolist())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "f1 = f1_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions)\n",
    "recall = recall_score(true_labels, predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "# Use the class weights in your loss function\n",
    "criterion = nn.BCELoss(weight=class_weights[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1603228896856308, Val Loss: 0.4320361314307056\n",
      "Epoch 2, Loss: 0.1396017223596573, Val Loss: 0.399829888507097\n",
      "Epoch 3, Loss: 0.9034870862960815, Val Loss: 0.24441474721924591\n",
      "Epoch 4, Loss: 0.005920471623539925, Val Loss: 0.27302157433417157\n",
      "Epoch 5, Loss: 0.014106993563473225, Val Loss: 0.1628223878501413\n",
      "Epoch 6, Loss: 0.002864101668819785, Val Loss: 0.1683755014643827\n",
      "Epoch 7, Loss: 0.03152022138237953, Val Loss: 0.14615272227339263\n",
      "Epoch 8, Loss: 0.0035317561123520136, Val Loss: 0.16568230441099902\n",
      "Epoch 9, Loss: 0.0016053959261626005, Val Loss: 0.1535709749060512\n",
      "Epoch 10, Loss: 0.000489936675876379, Val Loss: 0.13336837656235967\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch.view(-1, 1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            val_output = model(X_batch)\n",
    "            val_loss += criterion(val_output, y_batch.view(-1, 1)).item()\n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}, Val Loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9984491089374996\n",
      "F1 Score: 0.9549520247194665\n",
      "Precision: 0.971542025148908\n",
      "Recall: 0.93891909178126\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in val_loader:\n",
    "        outputs = model(X_batch)\n",
    "        predicted = (outputs > 0.5).float()  # Using 0.5 as the threshold for binary classification\n",
    "        predictions.extend(predicted.view(-1).tolist())\n",
    "        true_labels.extend(y_batch.tolist())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "f1 = f1_score(true_labels, predictions)\n",
    "precision = precision_score(true_labels, predictions)\n",
    "recall = recall_score(true_labels, predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20, 6))\n",
    "\n",
    "dff = df.copy()\n",
    "dff['DATE_TIME'] = pd.to_datetime(df['DATE_TIME'])\n",
    "dff = dff.set_index('DATE_TIME')\n",
    "\n",
    "dff[['BX', 'BY', 'BZ']].plot(ax=ax, alpha=0.25)\n",
    "#ax.plot(dff.index, dff['BX', 'BY', 'BZ'], color='black', alpha=0.25)\n",
    "for cme in y_train:\n",
    "    plt.plot_date(cme)\n",
    "    #ax.axvline(pd.Timestamp(cme), color='grey')\n",
    "#y_train.map(lambda cme: ax.axvline(cme, color='red'))\n",
    "#plt.axvline(y_train[cme])\n",
    "\n",
    "#plt.xlabel('date')\n",
    "plt.ylabel('magnetic field strength')\n",
    "plt.title('Result CME detection')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
