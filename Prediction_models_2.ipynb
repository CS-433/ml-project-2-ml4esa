{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Statistics (correlation)\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# libraries for the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions\n",
    "from pt_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data\n",
    "This is the clean data that we processed in the notebook `Training_data_preparation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"DATA/training_data/\"\n",
    "\n",
    "df = pd.read_csv(data_path + \"VEX_edac_mag_labeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE_TIME</th>\n",
       "      <th>EDAC</th>\n",
       "      <th>BX</th>\n",
       "      <th>BY</th>\n",
       "      <th>BZ</th>\n",
       "      <th>BT</th>\n",
       "      <th>XSC</th>\n",
       "      <th>YSC</th>\n",
       "      <th>ZSC</th>\n",
       "      <th>RSC</th>\n",
       "      <th>cme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-04-24 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>12.357658</td>\n",
       "      <td>-1.304164</td>\n",
       "      <td>-3.332425</td>\n",
       "      <td>12.881274</td>\n",
       "      <td>-4451.055178</td>\n",
       "      <td>-3196.485753</td>\n",
       "      <td>-65466.762260</td>\n",
       "      <td>65695.760575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-04-24 00:05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>12.868947</td>\n",
       "      <td>-0.980800</td>\n",
       "      <td>-3.360027</td>\n",
       "      <td>13.340680</td>\n",
       "      <td>-4202.246280</td>\n",
       "      <td>-3138.377907</td>\n",
       "      <td>-65806.350827</td>\n",
       "      <td>66015.078600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-04-24 00:10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>12.857438</td>\n",
       "      <td>-0.871986</td>\n",
       "      <td>-3.487877</td>\n",
       "      <td>13.355384</td>\n",
       "      <td>-3954.000329</td>\n",
       "      <td>-3080.233288</td>\n",
       "      <td>-66137.913808</td>\n",
       "      <td>66327.612616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-04-24 00:15:00</td>\n",
       "      <td>0</td>\n",
       "      <td>12.898635</td>\n",
       "      <td>-0.684986</td>\n",
       "      <td>-2.885689</td>\n",
       "      <td>13.248405</td>\n",
       "      <td>-3705.057257</td>\n",
       "      <td>-3021.761270</td>\n",
       "      <td>-66463.291041</td>\n",
       "      <td>66635.079608</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-04-24 00:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>12.766473</td>\n",
       "      <td>-0.517608</td>\n",
       "      <td>-2.217135</td>\n",
       "      <td>12.972905</td>\n",
       "      <td>-3453.676541</td>\n",
       "      <td>-2962.553108</td>\n",
       "      <td>-66784.717784</td>\n",
       "      <td>66939.596338</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE_TIME  EDAC         BX        BY        BZ         BT  \\\n",
       "0  2006-04-24 00:00:00     0  12.357658 -1.304164 -3.332425  12.881274   \n",
       "1  2006-04-24 00:05:00     0  12.868947 -0.980800 -3.360027  13.340680   \n",
       "2  2006-04-24 00:10:00     0  12.857438 -0.871986 -3.487877  13.355384   \n",
       "3  2006-04-24 00:15:00     0  12.898635 -0.684986 -2.885689  13.248405   \n",
       "4  2006-04-24 00:20:00     0  12.766473 -0.517608 -2.217135  12.972905   \n",
       "\n",
       "           XSC          YSC           ZSC           RSC  cme  \n",
       "0 -4451.055178 -3196.485753 -65466.762260  65695.760575    0  \n",
       "1 -4202.246280 -3138.377907 -65806.350827  66015.078600    0  \n",
       "2 -3954.000329 -3080.233288 -66137.913808  66327.612616    0  \n",
       "3 -3705.057257 -3021.761270 -66463.291041  66635.079608    0  \n",
       "4 -3453.676541 -2962.553108 -66784.717784  66939.596338    0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate the feature matrix `X` and the labels `y`.\n",
    "- `X` will only contain EDAC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['cme'].values\n",
    "X = df['EDAC'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y: (893069,)\n",
      "Shape of X: (893069,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of y:\", y.shape)\n",
    "print(\"Shape of X:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net models with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EDACDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading EDAC data\"\"\"\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "# df['EDAC'] = StandardScaler().fit_transform(df[['EDAC']])\n",
    "# X = df['EDAC'].values\n",
    "# y = df['cme'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train.astype(np.float32)).unsqueeze(1)\n",
    "y_train = torch.tensor(y_train.astype(np.float32))\n",
    "X_test = torch.tensor(X_test.astype(np.float32)).unsqueeze(1)\n",
    "y_test = torch.tensor(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the weight for the positive class\n",
    "class_counts = df['cme'].value_counts()\n",
    "weight_for_1 = (1 / class_counts[1]) * (len(df) / 2.0)\n",
    "class_weight = torch.tensor([weight_for_1]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_f1(model, test_loader):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            outputs = model(data)\n",
    "            predicted = (outputs.squeeze() > 0.5).float()\n",
    "            all_predictions.extend(predicted.tolist())\n",
    "            all_targets.extend(target.tolist())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (np.array(all_predictions) == np.array(all_targets)).mean()\n",
    "    precision = precision_score(all_targets, all_predictions)\n",
    "    recall = recall_score(all_targets, all_predictions)\n",
    "    f1 = f1_score(all_targets, all_predictions)\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.857212493914893\n",
      "Epoch 2, Loss: 2.5224304377541498\n",
      "Epoch 3, Loss: 2.522657038353648\n",
      "Epoch 4, Loss: 2.5226548335530645\n",
      "Epoch 5, Loss: 2.522590469805219\n",
      "Epoch 6, Loss: 2.5226513884110036\n",
      "Epoch 7, Loss: 2.522955100485519\n",
      "Epoch 8, Loss: 2.5225262230856793\n",
      "Epoch 9, Loss: 2.5227583692129136\n",
      "Epoch 10, Loss: 2.5223924705938217\n",
      "Accuracy: 98.26833282945346%\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoaders\n",
    "train_dataset = EDACDataset(X_train, y_train)\n",
    "test_dataset = EDACDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Neural Network Model\n",
    "class EDACNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EDACNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 10)  # Adjust the number of neurons\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(10, 1)  # Output layer\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = EDACNet()\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.BCELoss(weight=class_weight)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output.squeeze(), target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}')\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer, epochs=10)\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            outputs = model(data)\n",
    "            predicted = (outputs.squeeze() > 0.5).float()\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Accuracy: {accuracy}%')\n",
    "\n",
    "# Note: This code is a basic template and might need adjustments based on your actual dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9827, Precision: 0.5000, Recall: 0.0003, F1 Score: 0.0006\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1 = evaluate_model_with_f1(model, test_loader)\n",
    "print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sequences with a window size of 36 (3 hours at 5 minutes per interval)\n",
    "window_size = 36  # 3 hours * 60 minutes / 5 minutes per interval\n",
    "X_sequence, y_sequence = create_sliding_window_sequences(X, y, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sequence, y_sequence, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train[:, :, np.newaxis], dtype=torch.float32)  # Adding an extra dimension for LSTM input\n",
    "y_train_tensor = torch.tensor(y_train[:, np.newaxis], dtype=torch.float32)  # Adding an extra dimension for LSTM output\n",
    "X_test_tensor = torch.tensor(X_test[:, :, np.newaxis], dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test[:, np.newaxis], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDatasets and DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "hidden_dim = 64\n",
    "num_layers = 1\n",
    "model = CMEPredictorLSTM(input_dim=1, hidden_dim=hidden_dim, num_layers=num_layers)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss() # Default\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.16208432614803314\n",
      "Epoch 2/30, Loss: 0.15603922307491302\n",
      "Epoch 3/30, Loss: 0.08715824782848358\n",
      "Epoch 4/30, Loss: 0.1595345139503479\n",
      "Epoch 5/30, Loss: 0.15877753496170044\n",
      "Epoch 6/30, Loss: 0.0164636243134737\n",
      "Epoch 7/30, Loss: 0.08726794272661209\n",
      "Epoch 8/30, Loss: 0.014458577148616314\n",
      "Epoch 9/30, Loss: 0.08719978481531143\n",
      "Epoch 10/30, Loss: 0.019636793062090874\n",
      "Epoch 11/30, Loss: 0.01625734195113182\n",
      "Epoch 12/30, Loss: 0.017482275143265724\n",
      "Epoch 13/30, Loss: 0.08742906898260117\n",
      "Epoch 14/30, Loss: 0.015229837968945503\n",
      "Epoch 15/30, Loss: 0.016985246911644936\n",
      "Epoch 16/30, Loss: 0.08731164038181305\n",
      "Epoch 17/30, Loss: 0.021854175254702568\n",
      "Epoch 18/30, Loss: 0.08728744834661484\n",
      "Epoch 19/30, Loss: 0.15459194779396057\n",
      "Epoch 20/30, Loss: 0.0871344655752182\n",
      "Epoch 21/30, Loss: 0.015069413930177689\n",
      "Epoch 22/30, Loss: 0.08745097368955612\n",
      "Epoch 23/30, Loss: 0.15746046602725983\n",
      "Epoch 24/30, Loss: 0.22909532487392426\n",
      "Epoch 25/30, Loss: 0.15996423363685608\n",
      "Epoch 26/30, Loss: 0.08787472546100616\n",
      "Epoch 27/30, Loss: 0.08721815794706345\n",
      "Epoch 28/30, Loss: 0.08708164840936661\n",
      "Epoch 29/30, Loss: 0.15381132066249847\n",
      "Epoch 30/30, Loss: 0.08740759640932083\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9825\n",
      "Precision: 1.0000\n",
      "Recall: 0.0019\n",
      "F1 Score: 0.0038\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    y_true = y_test_tensor.numpy()\n",
    "    y_pred = model(X_test_tensor).numpy()\n",
    "    y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary output\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1 = calculate_metrics(y_true, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the class weights for imbalanced classes\n",
    "class_counts = df['cme'].value_counts().sort_index().values\n",
    "weight_for_1 = (1 / class_counts[1]) * (len(df) / 2.0)\n",
    "weights = torch.tensor([weight_for_1], dtype=torch.float32)\n",
    "\n",
    "# Define the weighted loss function with pos_weight for the positive class\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Loss: 1.661719799041748\n",
      "Epoch 2/2, Loss: 1.6617088317871094\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass, use model with logits output (not passing through sigmoid)\n",
    "        outputs = model(inputs).squeeze()\n",
    "        \n",
    "        # Compute the loss, labels should be float and no need to squeeze if they are already 1D\n",
    "        loss = criterion(outputs, labels.float().view(-1))\n",
    "\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9824\n",
      "Precision: 0.4409\n",
      "Recall: 0.0131\n",
      "F1 Score: 0.0255\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    y_true = y_test_tensor.numpy()\n",
    "    y_pred = model(X_test_tensor).numpy()\n",
    "    y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary output\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1 = calculate_metrics(y_true, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
